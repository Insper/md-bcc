{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e37c0df-e67b-449d-8048-3be19047ab6d",
   "metadata": {},
   "source": [
    "# Exercicios com Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562f41a9-c638-4e0f-9493-77654a650474",
   "metadata": {},
   "source": [
    "Caso precise, abaixo estão os comandos para iniciar o container:\n",
    "\n",
    "Para macOS e linux, utilize:\n",
    "\n",
    "```bash\n",
    "docker run \\\n",
    "    -it \\\n",
    "    --rm \\\n",
    "    -p 8888:8888 \\\n",
    "    -p 4040:4040 \\\n",
    "    -v \"`pwd`\":/home/jovyan/work \\\n",
    "    jupyter/pyspark-notebook\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "Se estiver no Windows estes comandos, utilize:\n",
    "\n",
    "- No Powershell: `docker run -it --rm -p 8888:8888 -p 4040:4040 -v ${PWD}:/home/jovyan/work jupyter/pyspark-notebook`\n",
    "\n",
    "- No Prompt de comando: `docker run -it --rm -p 8888:8888 -p 4040:4040 -v %cd%:/home/jovyan/work jupyter/pyspark-notebook`\n",
    "\n",
    "Agora abra esse notebook lá no container!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7292d9-4aa8-47c3-938b-3922cd4be036",
   "metadata": {},
   "source": [
    "## Iniciando o Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c208f2-a1ef-4f30-bf7c-5ed01e20246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "conf.setAppName(\"Minha aplicação\")\n",
    "conf.setMaster(\"local[*]\")\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95e478c-cfe7-4bca-8ebf-6c34dd38aeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://67d134ed744b:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Minha aplicação</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Minha aplicação>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d74df",
   "metadata": {},
   "source": [
    "## Iniciando a biblioteca de correção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f05694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/macielcalebe/insperautograding.git\n",
      "  Cloning https://github.com/macielcalebe/insperautograding.git to /tmp/pip-req-build-lnbxzye6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/macielcalebe/insperautograding.git /tmp/pip-req-build-lnbxzye6\n",
      "  Resolved https://github.com/macielcalebe/insperautograding.git to commit acdda51152774d9e1a979b426e41daa7a8a7793c\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting python-dotenv (from insperautograder==0.2.0)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from insperautograder==0.2.0) (2.31.0)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.11/site-packages (from insperautograder==0.2.0) (8.16.1)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.11/site-packages (from insperautograder==0.2.0) (8.1.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython->insperautograder==0.2.0) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython->insperautograder==0.2.0) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython->insperautograder==0.2.0) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython->insperautograder==0.2.0) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython->insperautograder==0.2.0) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from ipython->insperautograder==0.2.0) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython->insperautograder==0.2.0) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython->insperautograder==0.2.0) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.11/site-packages (from ipython->insperautograder==0.2.0) (5.11.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython->insperautograder==0.2.0) (4.8.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->insperautograder==0.2.0) (0.1.4)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->insperautograder==0.2.0) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->insperautograder==0.2.0) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->insperautograder==0.2.0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->insperautograder==0.2.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->insperautograder==0.2.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->insperautograder==0.2.0) (2023.7.22)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython->insperautograder==0.2.0) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython->insperautograder==0.2.0) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->insperautograder==0.2.0) (0.2.8)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->insperautograder==0.2.0) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->insperautograder==0.2.0) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->insperautograder==0.2.0) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython->insperautograder==0.2.0) (1.16.0)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: insperautograder\n",
      "  Building wheel for insperautograder (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for insperautograder: filename=insperautograder-0.2.0-py3-none-any.whl size=4418 sha256=60bcf2fed9e7d43acc9bf06205bc2566d7cc6c2c09f5c7adc7a31ad2b98d6f1e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-luule69f/wheels/bb/01/cc/7f397587bfedd6c633e2627496c45d5693aa959ee8237ead1f\n",
      "Successfully built insperautograder\n",
      "Installing collected packages: python-dotenv, insperautograder\n",
      "Successfully installed insperautograder-0.2.0 python-dotenv-1.0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install git+https://github.com/macielcalebe/insperautograding.git\n",
    "\n",
    "import insperautograder.jupyter as ia\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e29fe40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|    | Atividade            | De                        | Até                       |\n",
       "|---:|:---------------------|:--------------------------|:--------------------------|\n",
       "|  0 | newborn              | 2024-02-01 03:00:00+00:00 | 2024-05-30 03:00:00+00:00 |\n",
       "|  1 | select01             | 2024-02-08 03:00:00+00:00 | 2024-02-19 02:59:59+00:00 |\n",
       "|  2 | ddl                  | 2024-02-22 03:00:00+00:00 | 2024-02-27 02:59:59+00:00 |\n",
       "|  3 | dml                  | 2024-02-26 03:00:00+00:00 | 2024-03-03 02:59:59+00:00 |\n",
       "|  4 | group_having         | 2024-02-29 03:00:00+00:00 | 2024-03-12 02:59:59+00:00 |\n",
       "|  5 | views                | 2024-02-29 03:00:00+00:00 | 2024-03-20 02:59:59+00:00 |\n",
       "|  6 | agg_join             | 2024-02-29 03:00:00+00:00 | 2024-03-05 02:59:59+00:00 |\n",
       "|  7 | sql_review1          | 2024-03-11 03:00:00+00:00 | 2024-03-20 02:59:59+00:00 |\n",
       "|  8 | permissions          | 2024-03-18 03:00:00+00:00 | 2024-03-26 02:59:59+00:00 |\n",
       "|  9 | desafio_normalizacao | 2024-03-21 03:00:00+00:00 | 2024-04-15 02:59:59+00:00 |\n",
       "| 10 | ai_md_23_1           | 2024-03-25 03:00:00+00:00 | 2024-04-01 15:00:00+00:00 |\n",
       "| 11 | ai_md_23_2           | 2024-03-25 03:00:00+00:00 | 2024-04-01 15:00:00+00:00 |\n",
       "| 12 | ai_md_24_1           | 2024-04-01 03:00:00+00:00 | 2024-04-01 18:35:00+00:00 |\n",
       "| 13 | triggers             | 2024-04-18 03:00:00+00:00 | 2024-04-27 02:59:59+00:00 |\n",
       "| 14 | functional           | 2024-04-25 03:00:00+00:00 | 2024-05-13 02:59:59+00:00 |\n",
       "| 15 | spark                | 2024-05-02 03:00:00+00:00 | 2024-05-16 02:59:59+00:00 |\n",
       "| 16 | exercicios_spark     | 2024-05-06 03:00:00+00:00 | 2024-05-20 02:59:59+00:00 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ia.tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d6f05ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|    | Atividade        | Exercício   |   Peso |   Nota |\n",
       "|---:|:-----------------|:------------|-------:|-------:|\n",
       "|  0 | exercicios_spark | ex01        |      1 |      0 |\n",
       "|  1 | exercicios_spark | ex02        |      1 |      0 |\n",
       "|  2 | exercicios_spark | ex03        |      1 |      0 |\n",
       "|  3 | exercicios_spark | ex04        |      1 |      0 |\n",
       "|  4 | exercicios_spark | ex05        |      1 |      0 |\n",
       "|  5 | exercicios_spark | ex06        |      1 |      0 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ia.grades(task=\"exercicios_spark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3099ef4-2117-47a8-8a1d-af2df7814056",
   "metadata": {},
   "source": [
    "## Trabalhando com Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483b1de3-9e55-46ce-99e8-526b05b8c3d2",
   "metadata": {},
   "source": [
    "Para este exercicio vamos trabalhar com o dataset de reviews da Amazon visto em https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews. Baixe o arquivo \"train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65caf38e-fbd8-4513-af02-37671c6a949b",
   "metadata": {},
   "source": [
    "Vamos ler o arquivo \"train.csv\" em um RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e64ec721-3b7f-46b8-a8a9-d27ccc83f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b73e675-ea3b-49c2-8622-53e8c17cfdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"2\",\"Stuning even for the non-gamer\",\"This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\"']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4794fc0-59cf-497f-98fc-d20efc0cca2b",
   "metadata": {},
   "source": [
    "De acordo com a documentação deste arquivo vista no Kaggle, cada linha contem 2 elementos: o sentimento do review (1 - negativo, 2 - positivo), o título e o corpo do review. A linha contem esses elementos em um formato \"comma-separated value\" (CSV), onde cada um dos campos está delimitado por aspas duplas. Se o texto em si (titulo ou corpo) contem aspas, elas aparecem como um par de aspas duplas. Vamos usar o `.filter()` para achar um exemplo desses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef3c736d-0378-43f7-be05-3e7f53b1423e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"2\",\"Amazing!\",\"This soundtrack is my favorite music of all time, hands down. The intense sadness of \"\"Prisoners of Fate\"\" (which means all the more if you\\'ve played the game) and the hope in \"\"A Distant Promise\"\" and \"\"Girl who Stole the Star\"\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"\"Chrono Cross ~ Time\\'s Scar~\"\", \"\"Time of the Dreamwatch\"\", and \"\"Chronomantique\"\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_line = rdd.filter(lambda x: '\"\"' in x).take(1)\n",
    "example_line = example_line[0]\n",
    "\n",
    "example_line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0e86d-122f-4c0e-bf36-a0a8e2f60559",
   "metadata": {},
   "source": [
    "Levando isso em consideração, vamos fazer uma função simples para separar os campos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4923aa8b-1bee-4c74-8d18-6f4cf0445b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    parts = line[1:-1].split('\",\"')\n",
    "    sentiment = int(parts[0])\n",
    "    title = parts[1].replace('\"\"', '\"')\n",
    "    body = parts[2].replace('\"\"', '\"')\n",
    "    return (sentiment, title, body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82f380c6-469c-4dd2-baa5-cbe72110de7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " 'Amazing!',\n",
       " 'This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_line(example_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8249e3-6f4a-4ed0-81b5-a453d141b88b",
   "metadata": {},
   "source": [
    "Podemos agora utilizar nossa função para separar os campos de cada linha do dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d103d0-ae4d-4912-ba1b-8133f12d4e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_split = rdd.map(parse_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64fbea0-1378-4be7-b1d7-ada7828735b4",
   "metadata": {},
   "source": [
    "Como de costume, nada realmente acontece até que uma \"action\" seja invocada. O `.map()` é uma \"transformation\". Vamos usar uma action simples para \"materializar\" o novo RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b670e5-1757-443b-a229-453e3e3115b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_split.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff144ad-9378-4b72-ae84-1b1d2dda815d",
   "metadata": {},
   "source": [
    "Vamos explorar os resultados para ver se deu certo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7882d9-4502-406b-abc4-b74de6fa1aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_split.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3317a957-f13d-49fe-b193-9c6826616cc7",
   "metadata": {},
   "source": [
    "**Atividade**: Implemente uma função que recebe o rdd processado e conte quantos sentimentos diferentes existem, e quantas vezes aparecem, para confirmar que só tem os sentimentos 1 e 2. Sua função deve retornar o resultado em tuplas, onde o primeiro elemento é o sentimento e o segundo é a contagem de vezes que aparece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ed566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex01(rdd_split):\n",
    "    # Seu código AQUI\n",
    "    return rdd_split # Pode alterar o retorno, se necessário!\n",
    "    \n",
    "ex01(rdd_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0248377",
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.sender(answer=\"ex01\", task=\"exercicios_spark\", question=\"ex01\", answer_type=\"pycode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe0feb-e926-485d-80c0-897bf7820e47",
   "metadata": {},
   "source": [
    "**Atividade**: Implemente uma função que recebe o rdd processado e retorna quantos reviews não tem titulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674cdb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex02(rdd_split):\n",
    "    # Seu código AQUI\n",
    "    return rdd_split # Pode alterar o retorno, se necessário!\n",
    "\n",
    "ex02(rdd_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.sender(answer=\"ex02\", task=\"exercicios_spark\", question=\"ex02\", answer_type=\"pycode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31da43c-d2a5-4806-a5bf-9765e7fb09f9",
   "metadata": {},
   "source": [
    "**Atividade**: Implemente uma função que recebe o rdd processado e retorna quantos reviews não tem corpo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex03(rdd_split):\n",
    "    # Seu código AQUI\n",
    "    return rdd_split # Pode alterar o retorno, se necessário!\n",
    "\n",
    "ex03(rdd_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.sender(answer=\"ex03\", task=\"exercicios_spark\", question=\"ex03\", answer_type=\"pycode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d3fd0-af72-4b2e-aa61-7ffc897b86c1",
   "metadata": {},
   "source": [
    "**Atividade**: Implemente uma função que recebe o rdd processado e retorna qual o comprimento máximo de um título e de um corpo. O resultado deve ser uma tupla com os dois valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f286058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex04(rdd_split):\n",
    "    # Seu código AQUI\n",
    "    return rdd_split # Pode alterar o retorno, se necessário!\n",
    "    \n",
    "ex04(rdd_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.sender(answer=\"ex04\", task=\"exercicios_spark\", question=\"ex04\", answer_type=\"pycode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d96887-6d6d-494e-9ac0-0c06b5c08dc6",
   "metadata": {},
   "source": [
    "**Atividade**: Implemente uma função que recebe o rdd processado e retorna qual a maior palavra palíndroma sem pontuações do dataset (no titulo ou corpo) e seu tamanho. Para este exercício, está permitido o uso de list comprehensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6df655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1755cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex05(rdd_split):\n",
    "    # Seu código AQUI\n",
    "    return rdd_split # Pode alterar o retorno, se necessário!\n",
    "\n",
    "ex05(rdd_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa180dd-b4ca-4db5-a2fd-c3c33818abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.sender(answer=\"ex05\", task=\"exercicios_spark\", question=\"ex05\", answer_type=\"pycode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63f641d-1d98-4d84-8f7b-93b122ae057c",
   "metadata": {},
   "source": [
    "**Atividade**: Implemente uma função que recebe o rdd processado e retorna as 20 palavras mais populares do titulo com sua frequência absoluta. Teste no subconjunto apresentado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex06(rdd_split):\n",
    "    # Seu código AQUI\n",
    "    return rdd_split # Pode alterar o retorno, se necessário!\n",
    "\n",
    "ex06(rdd_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e4518",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_redux = rdd_split.sample(False, 0.05, 7)\n",
    "ex06(rdd_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a18e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.sender(answer=\"ex06\", task=\"exercicios_spark\", question=\"ex06\", answer_type=\"pycode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb5ee10",
   "metadata": {},
   "source": [
    "## Conferir notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc0d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4bb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.grades(task=\"exercicios_spark\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
